{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((4, 4)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((4, 4)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='softmax'),\n",
    "    layers.Dense(16,activation=tf.keras.activations.relu),\n",
    "    layers.Dense(2,activation = tf.keras.activations.sigmoid),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input):\n",
    "    image = tf.io.read_file(input)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./camdata_pre\"\n",
    "dir_list = natsort.natsorted(os.listdir(path))\n",
    "\n",
    "img_list = []\n",
    "\n",
    "for item in dir_list:\n",
    "    image_path = os.path.join(path, item)\n",
    "    \n",
    "    img_list.append(resize_image(image_path))\n",
    "    \n",
    "    # 이미지 파일 이름에서 레이블 추출\n",
    "    \n",
    "    \n",
    "csv_label = pd.read_csv('./dt.csv')\n",
    "\n",
    "img_array = np.array(img_list)\n",
    "label_array = np.array(csv_label)\n",
    "# print(img_array)\n",
    "# print(label_array)\n",
    "\n",
    "label_array = label_array.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 138ms/step - loss: 0.2800 - accuracy: 0.8179\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.2794 - accuracy: 0.8466\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.2790 - accuracy: 0.8466\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2785 - accuracy: 0.8466\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2782 - accuracy: 0.8466\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2778 - accuracy: 0.8466\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2775 - accuracy: 0.8466\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2773 - accuracy: 0.8466\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.2770 - accuracy: 0.8466\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2767 - accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "model.fit(img_array, label_array, epochs=10)\n",
    "playsound('done.m4a')\n",
    "model.save('ddundiV2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_for_predict(image_path):\n",
    "    image1 = tf.io.read_file(image_path)\n",
    "    image1 = tf.image.decode_image(image1, channels=3)\n",
    "    image1 = tf.cast(image1, tf.float32) / 255.0\n",
    "    image1 = tf.image.resize(image1, img_size)\n",
    "    image1 = np.expand_dims(image1, axis=0)  # 배치 차원 추가\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0.49500477 0.5184331 ]]\n",
      "shell  0.00s user 0.00s system 433% cpu 0.001 total\n",
      "children  0.00s user 0.00s system 0% cpu 0.001 total\n"
     ]
    }
   ],
   "source": [
    "modell = tf.keras.models.load_model('ddundiV2.h5')\n",
    "# print(img_list[4])\n",
    "\n",
    "x = resize_image_for_predict('./camdata_pre/1_.jpg')\n",
    "\n",
    "prediction = modell.predict(x)\n",
    "print(prediction)\n",
    "!time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
